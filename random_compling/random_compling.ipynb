{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разные задачи по обработке текста\n",
    "\n",
    "1. Распознавание текста с картинки (OCR, optical character recognition)\n",
    "2. Анализ тональности (sentiment analysis)\n",
    "3. Исправление опечаток (спеллчекер / автокоррект)\n",
    "4. Контекстуализированные семантические модели (BERT, ELMO)\n",
    "\n",
    "Библиотеки (+ их зависимости)\n",
    "```\n",
    "pytesseract\n",
    "dostoevsky\n",
    "langdetect\n",
    "autocorrect\n",
    "allennlp\n",
    "bert_embedding\n",
    "sklearn\n",
    "gensim\n",
    "```\n",
    "\n",
    "ПО\n",
    "```\n",
    "tesseract\n",
    "```\n",
    "\n",
    "Модели\n",
    "```\n",
    "http://vectors.nlpl.eu/repository/20/195.zip\n",
    "http://vectors.nlpl.eu/repository/20/181.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распознавание текста\n",
    "\n",
    "Оптическое распознавание символов (OCR, optical character recognition) - задача распознавания символов на изображении. Оно применяется, например, при оцифровке книг, в машинном переводе (функция перевода по фото в современных переводчиках, например Яндекс.Переводчике).\n",
    "\n",
    "Одним из популярных бесплатных вариантов является tesseract, который имеет библиотеку для питона, чтобы легко это интегрировать в код."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе [тьюториала](https://towardsdatascience.com/optical-character-recognition-ocr-with-less-than-12-lines-of-code-using-python-48404218cccb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считываем картинку с помощью библиотеки OpenCV, одной из основных для работы с изображениями\n",
    "2. Обрабатываем, указывая язык для лучшей работы, получаем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(filename, lang=\"eng\"):\n",
    "    img = cv2.imread(filename)\n",
    "    result = pytesseract.image_to_string(img, lang=lang)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./test_eng_easy.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical character recognition (OCR)\n",
      "Given an image representing printed text, determine the corresponding text.\n",
      "\n",
      "Speech recognition\n",
      "Given a sound clip of a person or people speaking, determine the textual\n",
      "representation of the speech. This is the opposite of text to speech and is\n",
      "one of the extremely difficult problems colloquially termed \"Al-complete\" (see\n",
      "above). In natural speech there are hardly any pauses between successive\n",
      "words, and thus speech segmentation is a necessary subtask of speech\n",
      "recognition (see below). In most spoken languages, the sounds representing\n",
      "successive letters blend into each other in a process termed coarticulation,\n",
      "so the conversion of the analog signal to discrete characters can be a very\n",
      "difficult process. Also, given that words in the same language are spoken by\n",
      "people with different accents, the speech recognition software must be able\n",
      "to recognize the wide variety of input as being identical to each other in terms\n",
      "of its textual equivalent.\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "result = ocr('test_eng_easy.png', lang=\"eng\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_rus_easy.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Местоимёние (лат. ргопотеп) — самостоятельная часть речи, которая указывает на предметы,\n",
      "признаки, количество, но не называет их, то есть заменяет существительное, прилагательное и\n",
      "числительное.\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "result = ocr('test_rus_easy.png', lang=\"rus\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_rus_tolstoy.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ГЛАВА 1.\n",
      "УЧИТЕЛЬ КАРЛ ИВАНЫЧ.\n",
      "\n",
      "42-го августа 18....’ровно в третий день после дня моего рож-\n",
      "дения, в который мне минуло десять лет и в который я полу-\n",
      "чил такие чудесные подарки, в 7 часов утра Карл Иваныч раз-\n",
      "будил меня, ударив над самой моей головой хлопушкой — из\n",
      "сахарной бумаги на палке—по мухе. Он сделал это так неловко,\n",
      "что задел образок моего ангела, висевший на дубовой спинке\n",
      "кровати, и что убитая муха упала мне прямо на голову. Я вы-\n",
      "сунул нос иг-под одеяла, остановил рукою образок, который\n",
      "продолжел качаться, скинул убитую муху на пол и, хотя ва-\n",
      "спанными, но сердитыми глазами окинул Карла Иваныча. Он\n",
      "эке, в пестром ваточном халате, подпоясанном поясом из той\n",
      "же материи, в красной вязаной ермолке © кисточкой и в мяг-\n",
      "ких козловых сапогах, продолжал ходить около стен, прице-\n",
      "ливаться и хлопать.\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "result = ocr('test_rus_tolstoy.png', lang=\"rus\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ошибки (иг-под, ©), но в целом неплохо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ тональности текста\n",
    "\n",
    "Анализ тональности текста - это задача определения настроения текста, обычно положительный / отрицательный / нейтральный, но есть варианты, где распознаются эмоции, как в text2emotion.\n",
    "\n",
    "Для русского есть библиотека dostoevsky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "model = FastTextSocialNetworkModel(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всё довольно неплохо -> {'positive': 0.9777238368988037, 'negative': 0.4378334879875183}\n",
      "здесь нет ничего хорошего -> {'neutral': 0.6442351341247559, 'negative': 0.08270734548568726}\n",
      "всё очень плохо -> {'negative': 0.7606606483459473, 'positive': 0.5000100135803223}\n",
      "просто ужасно -> {'negative': 0.9814634323120117, 'skip': 0.053413331508636475}\n",
      "замечательно сказано -> {'positive': 0.9553291201591492, 'skip': 0.031153826043009758}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    \"всё довольно неплохо\",\n",
    "    \"здесь нет ничего хорошего\",\n",
    "    \"всё очень плохо\",\n",
    "    \"просто ужасно\",\n",
    "    \"замечательно сказано\"\n",
    "]\n",
    "\n",
    "results = model.predict(messages, k=2)\n",
    "\n",
    "for message, sentiment in zip(messages, results):\n",
    "    print(message, '->', sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение языка\n",
    "\n",
    "При работе с большими данными часто нужно разделить данные на группы по языкам, чтобы отправить на обработку в разные модели, например. Для этого есть разные инструменты, например, основанные на простом распределении частотности букв, на словарях, с нейросетевым подходом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, detect_langs\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dschinghis Khan - Moskau\n",
    "detect(\"Moskau — Tor zur Vergangenheit, Spiegel der Zarenzeit, Rot wie das Blut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[de:0.9999953675874701]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_langs(\"Moskau — Tor zur Vergangenheit, Spiegel der Zarenzeit, Rot wie das Blut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто бывает так, что на коротких текстах библиотека ошибается и выдает какие-то другие языки, чаще всего родственные или со схожим алфавитом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mk:0.8192481473701985, bg:0.18075185259138762]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_langs(\"Привет!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ru:0.9999985230201999]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_langs(\"Привет, ты как?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[it:0.999994096312886]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ricchi E Poveri - Voulez Vous Danser\n",
    "\n",
    "detect_langs(\"\"\"\n",
    "Questa musica è un'isola in mezzo al mare\n",
    "basta chiudere gli occhi e saprai dovè\n",
    "devi solo sapertele conquistare\n",
    "voulez-vous voulez-vous voulez-vous danser?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бывает внезапное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cs:0.8571396370596909, fr:0.14285596647041326]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_langs(\"Voulez-vous, voulez-vous, voulez-vous danser?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[fr:0.5714290893675289, nl:0.42857062095631704]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_langs(\"Voulez-vous danser?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать свою модель, например, по википедии посчитав распределение букв в разных языках и выдавая ближайший вектор распредлеения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спеллчекер / автокоррект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Автоматическое исправление опечаток - это большая задача. Обычно этим занимаются компании, работающие с текстовым вводом:\n",
    "\n",
    "- редакторы документов (Word, Google Docs)\n",
    "- различные исправляющие сервисы (Grammarly)\n",
    "- клавиатуры для мобильных устройств (Google, Yandex, любые другие)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sleepy and there is no place I'm going to.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell(\"I'm not sleapy and tehre is no place I'm giong to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.2 ms ± 12.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit spell(\"There is no comin to consiousnes without pain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ускорить работу до скорости меньше миллисекунды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller(fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 µs ± 6.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit spell(\"There is no comin to consiousnes without pain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Продвинутые семантические модели\n",
    "\n",
    "Кроме Word2Vec и FastText есть и другие модели. Например, ELMO и BERT. Это контекстуализированные модели, которые выдают словам вектора в зависимости от контекста, то есть у одного слова может быть много векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import batch_to_ids, Elmo\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель, она хранится в виде двух файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_file = f'./195/options.json'\n",
    "weight_file = f'./195/model.hdf5'\n",
    "elmo = Elmo(options_file, weight_file, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовим текст: разделяем на предложения, убираем пунтктуацию и делим на токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Качество понимания зависит от множества факторов: от языка, от национальной культуры, от самого собеседника и т.д. Вот некоторые примеры сложностей, с которыми сталкиваются системы понимания текстов.\"\n",
    "sentences = [[w for w in wordpunct_tokenize(t) if w.isalpha()] for t in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 10]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i) for i in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем символы в численные ID, получаем результат из модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_ids = batch_to_ids(sentences)\n",
    "embeddings = elmo(character_ids)['elmo_representations'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер: число предложений * максимальное число слов * длину вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 1024])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаем в виде numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Качество [-0.5750413  -0.61228836]\n",
      "0 1 понимания [0.4107303 0.37982  ]\n",
      "0 2 зависит [-0.         0.6076344]\n",
      "0 3 от [-0. -0.]\n",
      "0 4 множества [-0.5212345  0.       ]\n",
      "0 5 факторов [-0.       2.53252]\n",
      "0 6 от [-0.68817264  0.5368072 ]\n",
      "0 7 языка [0.15810597 0.        ]\n",
      "0 8 от [-0.5423489   0.39302012]\n",
      "0 9 национальной [0. 0.]\n",
      "0 10 культуры [0.        2.6981413]\n",
      "0 11 от [-0.  0.]\n",
      "0 12 самого [-0.03170997  0.        ]\n",
      "0 13 собеседника [0.        2.0284185]\n",
      "0 14 и [0.13750097 1.2196429 ]\n",
      "0 15 т [0.9135562 0.       ]\n",
      "0 16 д [0.5173399 0.       ]\n",
      "1 0 Вот [ 0. -0.]\n",
      "1 1 некоторые [-0.         2.0123093]\n",
      "1 2 примеры [-0. -0.]\n",
      "1 3 сложностей [-1.0001913 -0.       ]\n",
      "1 4 с [-0.          0.41697437]\n",
      "1 5 которыми [0. 0.]\n",
      "1 6 сталкиваются [-0.3549805  1.514188 ]\n",
      "1 7 системы [-0.  0.]\n",
      "1 8 понимания [-0.4442916   0.31523082]\n",
      "1 9 текстов [-0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for idxs, sentence in enumerate(sentences):\n",
    "    for idxw, word in enumerate(sentence):\n",
    "        print(idxs, idxw, word, embeddings[idxs][idxw][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo(text):\n",
    "    text = [[w for w in wordpunct_tokenize(text) if w.isalpha()]]\n",
    "    character_ids = batch_to_ids(text)\n",
    "    embeddings = elmo(character_ids)['elmo_representations'][0]\n",
    "    embeddings = embeddings.detach().numpy()[0]\n",
    "    return embeddings.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем сходство предложений с помощью попарного сходства усредненных векторов предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.38279152, 0.38063884],\n",
       "       [0.38279152, 1.0000001 , 0.70891595],\n",
       "       [0.38063884, 0.70891595, 0.9999996 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Модель уверенно шла по подиуму.\",\n",
    "    \"Модель очень долго обучалась, но показала хорошее качество.\",\n",
    "    \"Модель очень медленно обучалась и продемонстрировала отличное качество.\"\n",
    "]\n",
    "\n",
    "vectors = [get_elmo(s) for s in sentences]\n",
    "\n",
    "cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим для FastText, НЕ контекстуализированной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText, KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load(\"./181/model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext(text):\n",
    "    text = [w for w in wordpunct_tokenize(text) if w.isalpha()]\n",
    "    vectors = [model.get_vector(w) for w in text]\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000001 , 0.5750117 , 0.5881903 ],\n",
       "       [0.5750117 , 0.99999994, 0.8338799 ],\n",
       "       [0.5881903 , 0.8338799 , 0.9999998 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = [get_fasttext(s) for s in sentences]\n",
    "\n",
    "cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат примерно такой же."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT - тоже контекстуализированная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The model walked confidently on the catwalk.\",\n",
    "    \"The model was trained for a very long time, but showed good quality.\",\n",
    "    \"The model was trained very slowly and showed excellent quality.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding = BertEmbedding(model='bert_12_768_12', dataset_name='book_corpus_wiki_en_cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_embedding(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.81107104, 0.83175623],\n",
       "       [0.81107104, 0.99999976, 0.9435316 ],\n",
       "       [0.83175623, 0.9435316 , 1.0000005 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([np.array(i[1]).mean(axis=0) for i in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат схожий.\n",
    "\n",
    "Не всегда нужно использовать очень сложные модели, часто можно обойтись чем-то попроще."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
