{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "vector_models_21-22.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Векторные модели. Word2Vec\n",
        "\n",
        "+ Firth (1957:11):\n",
        "You shall know a word by the company it keeps . . .\n",
        "\n",
        "+ Дистрибутивная гипотеза: значение слова определяется его контекстом — иначе говоря, словами, которые встречаются рядом с этим словом в тексте. \n",
        "\n",
        "+ Область лингвистики, которая занимается вычислением степени семантической близости между словами/текстами и т.п. на основании их распределения (дистрибуции) в больших массивах данных (текстовых корпусах) назвается **дистрибутивной семантикой**."
      ],
      "metadata": {
        "id": "NdJYiJAUVEHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кратко о существующих системах\n",
        "\n",
        "**GloVe**\n",
        "\n",
        "GloVe берет и строит полную матрицу совместной встречаемости и после этого с помощью алгоритомв уменьшения размерности преобразует ее так, чтобы вектора были опредленной длины\n",
        "\n",
        "\n",
        "**Word2Vec**\n",
        "\n",
        "Это уже нейросеть и она на основе корпуса постепенно подбирает коэффициенты (значения в векторах) для каждого слова так, чтобы с помощью них можно было наилучшим образом предсказывать слова по контексту\n",
        "\n",
        "**FastText**\n",
        "\n",
        "Если мы берем конкретные слова, мы не можем ничего сказать о тех, что нам не встретились (например, уже видели вагон и строитель, а вот вагоностроителя у нас не было). Если мы возьмем слова не целиком, а в виде будквенных нграмм, то мы сможем сложить неизвестные слова.\n",
        "\n",
        "**AdaGram**\n",
        "\n",
        "Все предыдущие модели основаны на графических оболочках и не учитывают многозначность и омонимию. Есть только один вектор для слова \"ключ\" и мы ничего с этим не можем сделать. AdaGram исходит из предположения, что у слова есть n вариантов и если они действительно отличаются и достаточно часто встречаются, он умеет их разделить.\n",
        "\n",
        "**BERT и ELMo**\n",
        "\n",
        "Эти модели не просто могут отличить значения слов, о и скорректировать их вектора в зависимости от контекста, например, понять, что в отрывках “чистый ключ в лесной чаще” и “ключ от квартиры” совсем разные “ключи”. https://habr.com/ru/post/487358/"
      ],
      "metadata": {
        "id": "aTBd1rztVEHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2Vec"
      ],
      "metadata": {
        "id": "9mMfbQjeVEHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Одной из самых известных моделей для работы с дистрибутивной семантикой является word2vec. Технология основана на нейронной сети, предсказывающей вероятность встретить слово в заданном контексте. Этот инструмент был разработан группой исследователей Google в 2013 году, руководителем проекта был Томаш Миколов (сейчас работает в Facebook). Вот две самые главные статьи:\n",
        "\n",
        "+ [Efficient Estimation of Word Representations inVector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
        "+ [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)\n",
        "\n",
        "Полученные таким образом вектора называются распределенными представлениями слов, или **эмбеддингами**."
      ],
      "metadata": {
        "id": "iGjcLmigVEHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как это обучается?\n",
        "\n",
        "Мы задаём вектор для каждого слова с помощью матрицы $w$ и вектор контекста с помощью матрицы $W$. По сути, word2vec является обобщающим названием для двух архитектур Skip-Gram и Continuous Bag-Of-Words (CBOW).\n",
        "\n",
        "+ **CBOW** предсказывает текущее слово, исходя из окружающего его контекста.\n",
        "\n",
        "+ **Skip-gram**, наоборот, использует текущее слово, чтобы предугадывать окружающие его слова.\n",
        "  \n",
        "\n",
        "![cbow_skip-gram](./cbow_skip-gram.png)\n",
        "\n",
        "\n",
        "#### Как это работает?\n",
        "\n",
        "Word2vec принимает большой текстовый корпус в качестве входных данных и сопоставляет каждому слову вектор, выдавая координаты слов на выходе. Сначала он создает словарь, «обучаясь» на входных текстовых данных, а затем вычисляет векторное представление слов. Векторное представление основывается на контекстной близости: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, согласно дистрибутивной гипотезе, имеющие схожий смысл), в векторном представлении будут иметь близкие координаты векторов-слов. Для вычисления близости слов используется косинусное расстояние между их векторами.\n",
        "\n",
        "С помощью дистрибутивных векторных моделей можно строить семантические пропорции (они же аналогии) и решать примеры:\n",
        "\n",
        "+ король: мужчина = королева: женщина $\\Rightarrow$\n",
        "+ король - мужчина + женщина = королева\n",
        "\n",
        "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)\n",
        "\n",
        "Ещё про механику с картинками [тут](https://habr.com/ru/post/446530/)\n",
        "\n",
        "#### Зачем это нужно?\n",
        "\n",
        "+ используется для решения семантических задач\n",
        "+ давайте подумаем, для описания каких семантических классов слов дистрибутивная информация особенно важна?\n",
        "+ несколько интересных статей по дистрибутивной семантике:\n",
        "\n",
        "* [Turney and Pantel 2010](https://jair.org/index.php/jair/article/view/10640)\n",
        "* [Lenci 2018](https://www.annualreviews.org/doi/abs/10.1146/annurev-linguistics-030514-125254?journalCode=linguistics)\n",
        "* [Smith 2019](https://arxiv.org/pdf/1902.06006.pdf)\n",
        "* [Pennington et al. 2014](https://www.aclweb.org/anthology/D14-1162/)\n",
        "* [Faruqui et al. 2015](https://www.aclweb.org/anthology/N15-1184/)\n",
        "\n",
        "+ подаётся на вход нейронным сетям\n",
        "+ используется в Siri, Google Assistant, Alexa, Google Translate...\n",
        "\n",
        "#### Gensim\n",
        "\n",
        "Использовать предобученную модель эмбеддингов или обучить свою можно с помощью библиотеки `gensim`. Вот ее [документация](https://radimrehurek.com/gensim/models/word2vec.html). Вообще-то `gensim` — библиотека для тематического моделирования текстов, но один из компонентов в ней — реализация на python алгоритмов из библиотеки word2vec (которая в оригинале была написана на C++).\n",
        "\n",
        "Если gensim у вас не стоит, то ставим: `pip install gensim`. Можно сделать это прямо из jupyter'а! Чтобы выполнить какую-то команду не в питоне, в командной строке, нужно написать перед ней восклицательный знак.\n"
      ],
      "metadata": {
        "id": "iXS3fmb3VEHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import gensim\n",
        "import logging\n",
        "import urllib.request\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ez-sfIRwVEHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как обучить свою модель\n",
        "\n",
        "NB! Обратите внимание, что тренировка модели не включает препроцессинг! Это значит, что избавляться от пунктуации, приводить слова к нижнему регистру, лемматизировать их, проставлять частеречные теги придется до тренировки модели (если, конечно, это необходимо для вашей задачи). Т.е. в каком виде слова будут в исходном тексте, в таком они будут и в модели.\n",
        "\n",
        "Поскольку иногда тренировка модели занимает много времени, то можно ещё вести лог событий, чтобы понимать, что на каком этапе происходит."
      ],
      "metadata": {
        "id": "KkeVx8z_VEHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "outputs": [],
      "metadata": {
        "id": "DY_Db8XMVEHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На вход модели даем текстовый файл, каждое предложение на отдельной строчке. Вот игрушечный пример с текстом «Бедной Лизы». Он заранее очищен от пунктуации, приведен к нижнему регистру и лемматизирован."
      ],
      "metadata": {
        "id": "fm3i7Cc9VEIA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "f = 'liza_lem.txt'\n",
        "data = gensim.models.word2vec.LineSentence(f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "YUOUR5MHVEID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем модель. Основные параметры:\n",
        "\n",
        "+ данные должны быть итерируемым объектом\n",
        "+ size — размер вектора,\n",
        "+ window — размер окна наблюдения,\n",
        "+ min_count — мин. частотность слова в корпусе,\n",
        "+ sg — используемый алгоритм обучения (0 — CBOW, 1 — Skip-gram),\n",
        "+ sample — порог для downsampling'a высокочастотных слов,\n",
        "+ workers — количество потоков,\n",
        "+ alpha — learning rate,\n",
        "+ iter — количество итераций,\n",
        "+ max_vocab_size — позволяет выставить ограничение по памяти при создании словаря (т.е. если ограничение привышается, то низкочастотные слова будут выбрасываться). Для сравнения: 10 млн слов = 1Гб RAM."
      ],
      "metadata": {
        "id": "y9sWIvd_VEIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "%time model_liza = gensim.models.Word2Vec(data, size=300, window=5, min_count=2)#в последней версии vector_size"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-13 06:29:36,935 : INFO : collecting all words and their counts\n",
            "2021-10-13 06:29:36,937 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-10-13 06:29:36,944 : INFO : collected 1213 word types from a corpus of 3109 raw words and 392 sentences\n",
            "2021-10-13 06:29:36,947 : INFO : Loading a fresh vocabulary\n",
            "2021-10-13 06:29:36,952 : INFO : effective_min_count=2 retains 478 unique words (39% of original 1213, drops 735)\n",
            "2021-10-13 06:29:36,955 : INFO : effective_min_count=2 leaves 2374 word corpus (76% of original 3109, drops 735)\n",
            "2021-10-13 06:29:36,961 : INFO : deleting the raw counts dictionary of 1213 items\n",
            "2021-10-13 06:29:36,964 : INFO : sample=0.001 downsamples 83 most-common words\n",
            "2021-10-13 06:29:36,966 : INFO : downsampling leaves estimated 1817 word corpus (76.6% of prior 2374)\n",
            "2021-10-13 06:29:36,974 : INFO : estimated required memory for 478 words and 300 dimensions: 1386200 bytes\n",
            "2021-10-13 06:29:36,976 : INFO : resetting layer weights\n",
            "2021-10-13 06:29:37,089 : INFO : training model with 3 workers on 478 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2021-10-13 06:29:37,104 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-10-13 06:29:37,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-10-13 06:29:37,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-10-13 06:29:37,111 : INFO : EPOCH - 1 : training on 3109 raw words (1778 effective words) took 0.0s, 103236 effective words/s\n",
            "2021-10-13 06:29:37,132 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-10-13 06:29:37,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-10-13 06:29:37,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-10-13 06:29:37,148 : INFO : EPOCH - 2 : training on 3109 raw words (1828 effective words) took 0.0s, 86351 effective words/s\n",
            "2021-10-13 06:29:37,160 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-10-13 06:29:37,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-10-13 06:29:37,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-10-13 06:29:37,169 : INFO : EPOCH - 3 : training on 3109 raw words (1794 effective words) took 0.0s, 121494 effective words/s\n",
            "2021-10-13 06:29:37,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-10-13 06:29:37,184 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-10-13 06:29:37,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-10-13 06:29:37,192 : INFO : EPOCH - 4 : training on 3109 raw words (1808 effective words) took 0.0s, 102504 effective words/s\n",
            "2021-10-13 06:29:37,203 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-10-13 06:29:37,205 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-10-13 06:29:37,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-10-13 06:29:37,212 : INFO : EPOCH - 5 : training on 3109 raw words (1828 effective words) took 0.0s, 113411 effective words/s\n",
            "2021-10-13 06:29:37,215 : INFO : training on a 15545 raw words (9036 effective words) took 0.1s, 72334 effective words/s\n",
            "2021-10-13 06:29:37,217 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 239 ms, sys: 27.2 ms, total: 266 ms\n",
            "Wall time: 285 ms\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPWburxwVEIJ",
        "outputId": "b3c39d54-076e-44a4-d0d2-1c633a969a2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно нормализовать вектора, тогда модель будет занимать меньше RAM. Однако после этого её нельзя дотренировывать. Здесь используется L2-нормализация: вектора нормализуются так, что если сложить квадраты всех элементов вектора, в сумме получится 1."
      ],
      "metadata": {
        "id": "k5nM8QNkVEIL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "model_liza.init_sims(replace=True)\n",
        "model_path = \"liza.bin\"\n",
        "\n",
        "print(\"Saving model...\")\n",
        "model_liza.wv.save_word2vec_format(model_path, binary=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-13 06:31:32,942 : INFO : precomputing L2-norms of word weight vectors\n",
            "2021-10-13 06:31:32,958 : INFO : storing 478x300 projection weights into liza.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model...\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOPh3pCZVEIM",
        "outputId": "d743d4c0-d09f-4c9a-e95d-87dde554b4e4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Смотрим, сколько в модели слов:"
      ],
      "metadata": {
        "id": "oOHpqJghVEIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "print(len(model_liza.wv.vocab))#len(model_liza.wv.key_to_index)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "478\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAHJm1FhVEIR",
        "outputId": "60229c9b-ef14-46db-b9fd-f5b63f7bed55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "print(sorted([w for w in model_liza.wv.vocab]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['анюта', 'армия', 'ах', 'барин', 'бедный', 'белый', 'берег', 'березовый', 'беречь', 'бесчисленный', 'благодарить', 'бледный', 'блеснуть', 'блестящий', 'близ', 'бог', 'богатый', 'большой', 'бояться', 'брать', 'бросать', 'бросаться', 'бывать', 'быть', 'важный', 'ввечеру', 'вдова', 'велеть', 'великий', 'великолепный', 'верить', 'верно', 'весело', 'веселый', 'весна', 'вести', 'весь', 'весьма', 'ветвь', 'ветер', 'вечер', 'взглядывать', 'вздох', 'вздыхать', 'взор', 'взять', 'вид', 'видеть', 'видеться', 'видный', 'вместе', 'вода', 'возвращаться', 'воздух', 'война', 'воображать', 'воображение', 'воспоминание', 'восторг', 'восхищаться', 'время', 'все', 'вслед', 'вставать', 'встречаться', 'всякий', 'высокий', 'выть', 'выходить', 'глаз', 'глубокий', 'гнать', 'говорить', 'год', 'голос', 'гора', 'горе', 'горестный', 'горлица', 'город', 'горький', 'господь', 'гром', 'грусть', 'давать', 'давно', 'далее', 'дверь', 'движение', 'двор', 'девушка', 'дело', 'день', 'деньги', 'деревня', 'деревянный', 'десять', 'добро', 'добрый', 'довольно', 'доживать', 'долго', 'должный', 'дом', 'домой', 'дочь', 'древний', 'друг', 'другой', 'дуб', 'думать', 'душа', 'едва', 'ехать', 'жалобный', 'желание', 'желать', 'жениться', 'жених', 'женщина', 'жестокий', 'живой', 'жизнь', 'жить', 'забава', 'заблуждение', 'забывать', 'завтра', 'задумчивость', 'закраснеться', 'закричать', 'заря', 'здешний', 'здравствовать', 'зеленый', 'земля', 'златой', 'знать', 'ибо', 'играть', 'идти', 'имя', 'искать', 'исполняться', 'испугаться', 'история', 'исчезать', 'кабинет', 'казаться', 'какой', 'капля', 'карета', 'карман', 'картина', 'катиться', 'келья', 'клятва', 'колено', 'копейка', 'который', 'красота', 'крест', 'крестьянин', 'крестьянка', 'кровь', 'кроме', 'кто', 'купить', 'ландыш', 'ласка', 'ласковый', 'левый', 'лес', 'лететь', 'летний', 'лето', 'лиза', 'лизин', 'лизина', 'лицо', 'лишний', 'лодка', 'ложиться', 'луг', 'луч', 'любезный', 'любить', 'любовь', 'лютый', 'матушка', 'мать', 'место', 'месяц', 'мечта', 'милый', 'мимо', 'минута', 'многочисленный', 'могила', 'мой', 'молить', 'молиться', 'молния', 'молодой', 'молодость', 'молчать', 'монастырь', 'море', 'москва', 'москва-река', 'мочь', 'мрак', 'мрачный', 'муж', 'мы', 'мысль', 'наглядеться', 'надеяться', 'надлежать', 'надобно', 'называть', 'наступать', 'натура', 'находить', 'наш', 'небесный', 'небо', 'невинность', 'невинный', 'неделя', 'нежели', 'нежный', 'незнакомец', 'некоторый', 'непорочность', 'неприятель', 'несколько', 'никакой', 'никто', 'новый', 'ночь', 'обижать', 'облако', 'обманывать', 'обморок', 'образ', 'обращаться', 'обстоятельство', 'объятие', 'огонь', 'один', 'однако', 'окно', 'окрестности', 'он', 'она', 'они', 'оно', 'опираться', 'описывать', 'опустеть', 'освещать', 'оставаться', 'оставлять', 'останавливать', 'останавливаться', 'отвечать', 'отдавать', 'отец', 'отечество', 'отменно', 'отрада', 'очень', 'падать', 'память', 'пастух', 'первый', 'перемениться', 'переставать', 'песня', 'петь', 'печальный', 'писать', 'питать', 'плакать', 'побежать', 'побледнеть', 'погибать', 'подавать', 'подгорюниваться', 'подле', 'подозревать', 'подымать', 'поехать', 'пойти', 'показываться', 'поклониться', 'покойный', 'покрывать', 'покрываться', 'покупать', 'полагать', 'поле', 'помнить', 'поселянин', 'последний', 'постой', 'потуплять', 'поцеловать', 'поцелуй', 'правый', 'представляться', 'прежде', 'преклонять', 'прекрасный', 'прелестный', 'приводить', 'прижимать', 'принадлежать', 'принуждать', 'природа', 'приходить', 'приятно', 'приятный', 'провожать', 'продавать', 'проливать', 'простой', 'просыпаться', 'проходить', 'проч', 'прощать', 'прощаться', 'пруд', 'птичка', 'пылать', 'пять', 'работа', 'работать', 'радость', 'рассказывать', 'расставаться', 'рвать', 'ребенок', 'река', 'решаться', 'робкий', 'роза', 'розовый', 'роман', 'российский', 'роща', 'рубль', 'рука', 'сам', 'самый', 'свет', 'светиться', 'светлый', 'свидание', 'свирель', 'свободно', 'свое', 'свой', 'свойство', 'сделать', 'сделаться', 'сей', 'сердечный', 'сердце', 'сидеть', 'сие', 'сиять', 'сказать', 'сказывать', 'сквозь', 'скорбь', 'скоро', 'скрываться', 'слабый', 'слеза', 'слезать', 'слово', 'случаться', 'слушать', 'слышать', 'смерть', 'сметь', 'смотреть', 'собственный', 'соглашаться', 'солнце', 'спасать', 'спокойно', 'спокойствие', 'спрашивать', 'стадо', 'становиться', 'стараться', 'старуха', 'старушка', 'старый', 'статься', 'стена', 'сто', 'столь', 'стон', 'стонать', 'сторона', 'стоять', 'страшно', 'страшный', 'судьба', 'схватывать', 'счастие', 'счастливый', 'сын', 'таить', 'такой', 'твой', 'темный', 'тения', 'тихий', 'тихонько', 'томный', 'тот', 'трава', 'трепетать', 'трогать', 'ты', 'убивать', 'уверять', 'увидеть', 'увидеться', 'удерживать', 'удивляться', 'удовольствие', 'узнавать', 'улица', 'улыбка', 'уметь', 'умирать', 'унылый', 'упасть', 'услышать', 'утешение', 'утро', 'хижина', 'хлеб', 'ходить', 'холм', 'хороший', 'хотеть', 'хотеться', 'хотя', 'худо', 'худой', 'царь', 'цветок', 'целовать', 'час', 'часто', 'человек', 'чистый', 'читатель', 'чувствительный', 'чувство', 'чувствовать', 'чулок', 'шестой', 'шум', 'шуметь', 'щадить', 'щека', 'эраст', 'эрастов', 'это', 'я']\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8hCzvr1VEIU",
        "outputId": "8cb7eb94-427e-46f5-ab0b-2c79d42d74da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "И чему же мы ее научили? Попробуем оценить модель вручную, порешав примеры. Несколько дано ниже, попробуйте придумать свои."
      ],
      "metadata": {
        "id": "q0sQjKiTVEIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "model_liza.wv.most_similar(positive=[\"смерть\", \"любовь\"], negative=[\"печальный\"], topn=1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('великолепный', 0.17804057896137238)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bJE4Jc4VEIZ",
        "outputId": "a26b3425-993a-451b-844e-6e88bd8b3ddf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "model_liza.wv.most_similar(\"любовь\", topn=3)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('подле', 0.21174314618110657),\n",
              " ('деревня', 0.2064322531223297),\n",
              " ('рука', 0.17434054613113403)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIU8YNA_VEIa",
        "outputId": "6dc633d8-9f76-4943-d523-ce4bd4dece05"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "model_liza.wv.similarity(\"лиза\", \"эраст\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10097058"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOGRhxfnVEIc",
        "outputId": "fed60e6f-be80-4490-a67c-10d6ac04a23f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "model_liza.wv.doesnt_match(\"скорбь грусть слеза улыбка\".split())"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'слеза'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4tmwGsoHVEId",
        "outputId": "54bca41e-f13d-46d0-c456-5ab106b906b9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "model_liza.wv.words_closer_than(\"лиза\", \"эраст\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['свой',\n",
              " 'который',\n",
              " 'мочь',\n",
              " 'сказать',\n",
              " 'сей',\n",
              " 'сердце',\n",
              " 'мой',\n",
              " 'твой',\n",
              " 'хотеть',\n",
              " 'день',\n",
              " 'рука',\n",
              " 'друг',\n",
              " 'слеза',\n",
              " 'бог',\n",
              " 'любезный',\n",
              " 'смерть',\n",
              " 'жизнь',\n",
              " 'смотреть',\n",
              " 'лизин',\n",
              " 'добрый',\n",
              " 'свет',\n",
              " 'видеть',\n",
              " 'небо',\n",
              " 'приходить',\n",
              " 'бедный',\n",
              " 'тот',\n",
              " 'чувство',\n",
              " 'идти',\n",
              " 'она',\n",
              " 'прощаться',\n",
              " 'место',\n",
              " 'стоять',\n",
              " 'взор',\n",
              " 'река',\n",
              " 'удовольствие',\n",
              " 'лицо',\n",
              " 'казаться',\n",
              " 'бояться',\n",
              " 'город',\n",
              " 'роща',\n",
              " 'стадо',\n",
              " 'веселый',\n",
              " 'пять',\n",
              " 'рубль',\n",
              " 'дело',\n",
              " 'дуб',\n",
              " 'солнце',\n",
              " 'подле',\n",
              " 'вместе',\n",
              " 'проливать',\n",
              " 'наш',\n",
              " 'зеленый',\n",
              " 'брать',\n",
              " 'вечер',\n",
              " 'играть',\n",
              " 'весь',\n",
              " 'видеться',\n",
              " 'великий',\n",
              " 'страшный',\n",
              " 'мрачный',\n",
              " 'светлый',\n",
              " 'сказывать',\n",
              " 'сам',\n",
              " 'хотеться',\n",
              " 'задумчивость',\n",
              " 'блестящий',\n",
              " 'нежели',\n",
              " 'деревня',\n",
              " 'увидеться',\n",
              " 'колено',\n",
              " 'трогать',\n",
              " 'дверь',\n",
              " 'щадить',\n",
              " 'закраснеться',\n",
              " 'грусть',\n",
              " 'блеснуть',\n",
              " 'отменно',\n",
              " 'читатель',\n",
              " 'живой',\n",
              " 'светиться',\n",
              " 'восторг',\n",
              " 'оно',\n",
              " 'лес',\n",
              " 'ласка',\n",
              " 'убивать',\n",
              " 'беречь',\n",
              " 'двор']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClMC9jNOVEIf",
        "outputId": "47280ae2-2ea3-4c64-db36-75d3dea73790"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Параметры варьирования\n",
        "\n",
        "1) препроцессинг -- лемматизировать или нет, например, вдруг мы хотим посмотреть на морфологические пропорции? тогда лемматизировать не нужно\n",
        "\n",
        "2) размер корпуса -- чем больше, тем лучше, но! не для семантических задач -- для них важнее качество\n",
        "\n",
        "3) размер словаря\n",
        "\n",
        "4) negative samples\n",
        "\n",
        "5) количество итераций\n",
        "\n",
        "6) длина вектора -- 100-300 (судя по всему, >300 не сильно улучшает результаты)\n",
        "\n",
        "7) длина окна -- для синтаксических задач, примерно 4, для семантических задач, большое окно, 8, 10.\n",
        "\n",
        "Хорошая статья про сравнение моделей с варьированием параметров: https://www.aclweb.org/anthology/D14-1162.pdf"
      ],
      "metadata": {
        "id": "EZl_fECYVEIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как использовать готовую модель\n",
        "\n",
        "#### RusVectōrēs\n",
        "\n",
        "На сайте RusVectōrēs (https://rusvectores.org/ru/) собраны предобученные на различных данных модели для русского языка, а также можно поискать наиболее близкие слова к заданному, посчитать семантическую близость нескольких слов и порешать примеры с помощью «калькулятором семантической близости».\n",
        "\n",
        "Для других языков также можно найти предобученные модели — например, модели [fastText](https://fasttext.cc/docs/en/english-vectors.html) и [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
        "\n",
        "Ещё давайте посмотрим на **векторные романы** https://nevmenandr.github.io/novel2vec/"
      ],
      "metadata": {
        "id": "vPsDlgqQVEIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Работа с моделью\n",
        "\n",
        "Модели word2vec бывают разных форматов:\n",
        "\n",
        "+ .vec.gz — обычный файл\n",
        "+ .bin.gz — бинарник\n",
        "\n",
        "Загружаются они с помощью одного и того же класса `KeyedVectors`, меняется только параметр `binary` у функции `load_word2vec_format`.\n",
        "\n",
        "Если же эмбеддинги обучены не с помощью word2vec, то для загрузки нужно использовать функцию `load`. Т.е. для загрузки предобученных эмбеддингов `glove`, `fasttext`, `bpe` и любых других нужна именно она.\n",
        "\n",
        "Скачаем с RusVectōrēs модель для русского языка, обученную на НКРЯ образца 2015 г."
      ],
      "metadata": {
        "id": "v290agZHVEIk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
              " <http.client.HTTPMessage at 0x7febdedd5bd0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfgQDJYjVEIn",
        "outputId": "1ec78923-d60a-45d4-fa25-c49a4f6bfd41"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
        "\n",
        "if m.endswith('.vec.gz'):\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
        "elif m.endswith('.bin.gz'):\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
        "else:\n",
        "    model = gensim.models.KeyedVectors.load(m)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-13 06:34:39,254 : INFO : loading projection weights from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n",
            "2021-10-13 06:34:53,828 : INFO : loaded (281776, 300) matrix from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdJc7-q6VEIq",
        "outputId": "2f633668-9e2c-4b45-8898-431b80c8235f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Мини-исследование**: Давайте протестируем, выделяет ли модель функцию интенсификации в прилагательных? Например, *ужасный курильщик* может интерпретироваться как *человек, который много курит*, а не только как (не столько как) *очень плохой человек-курильщик*. Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
      ],
      "metadata": {
        "id": "w3UV2ZV4VEIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']"
      ],
      "outputs": [],
      "metadata": {
        "id": "_KWmL5JSVEIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Частеречные тэги нужны, поскольку это специфика скачанной модели - она была натренирована на словах, аннотированных их частями речи (и лемматизированных). NB! В названиях моделей на `rusvectores` указано, какой тегсет они используют (mystem, upos и т.д.)\n",
        "\n",
        "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:\n"
      ],
      "metadata": {
        "id": "YxKyzxJ_VEIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "for word in words:\n",
        "    # есть ли слово в модели? \n",
        "    if word in model:\n",
        "        print(word)\n",
        "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
        "        print(model[word][:10])\n",
        "        # выдаем 10 ближайших соседей слова:\n",
        "        for i in model.most_similar(positive=[word], topn=10):\n",
        "            # слово + коэффициент косинусной близости\n",
        "            print(i[0], i[1])\n",
        "        print('\\n')\n",
        "    else:\n",
        "        # Увы!\n",
        "        print('Увы, слова \"%s\" нет в модели!' % word)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-13 06:35:02,031 : INFO : precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хороший_A\n",
            "[ 0.00722357 -0.00361956  0.1272455   0.06584469  0.00709477 -0.02014845\n",
            " -0.02056034  0.01321563  0.13692418 -0.09624264]\n",
            "плохой_A 0.7463520765304565\n",
            "неплохой_A 0.6708558797836304\n",
            "отличный_A 0.6633436679840088\n",
            "превосходный_A 0.6079519987106323\n",
            "замечательный_A 0.586450457572937\n",
            "недурной_A 0.5322482585906982\n",
            "отменный_A 0.5168066024780273\n",
            "прекрасный_A 0.4982393980026245\n",
            "посредственный_A 0.49099433422088623\n",
            "приличный_A 0.48622459173202515\n",
            "\n",
            "\n",
            "плохой_A\n",
            "[-0.05218472  0.0307817   0.1459371   0.0151835   0.06219714  0.01153753\n",
            " -0.01169093  0.01818374  0.0955373  -0.10191503]\n",
            "хороший_A 0.7463520765304565\n",
            "дурной_A 0.6186875104904175\n",
            "скверный_A 0.6014161109924316\n",
            "отличный_A 0.5226833820343018\n",
            "посредственный_A 0.5061030983924866\n",
            "неважный_A 0.5021152496337891\n",
            "неплохой_A 0.49169060587882996\n",
            "никудышный_A 0.48035892844200134\n",
            "ухудшать_V 0.43680477142333984\n",
            "плохо_ADV 0.4314875304698944\n",
            "\n",
            "\n",
            "ужасный_A\n",
            "[-0.05553271 -0.03172469  0.01998607  0.00171507 -0.00935555 -0.0296017\n",
            "  0.05394973  0.01597532 -0.03785459 -0.02099892]\n",
            "страшный_A 0.8007251024246216\n",
            "жуткий_A 0.6982528567314148\n",
            "отвратительный_A 0.6798903942108154\n",
            "ужасающий_A 0.6174501180648804\n",
            "чудовищный_A 0.6100856065750122\n",
            "постыдный_A 0.6009703278541565\n",
            "невероятный_A 0.5827822685241699\n",
            "ужасать_V 0.5815353393554688\n",
            "кошмарный_A 0.5675790309906006\n",
            "позорный_A 0.5351496338844299\n",
            "\n",
            "\n",
            "жуткий_A\n",
            "[-0.07627533 -0.06143281 -0.02622319 -0.03769541 -0.00350412 -0.01479934\n",
            "  0.03325103  0.06712756 -0.0044996   0.0145266 ]\n",
            "ужасный_A 0.6982529163360596\n",
            "страшный_A 0.6917036771774292\n",
            "зловещий_A 0.6490101218223572\n",
            "странный_A 0.6009964942932129\n",
            "отвратительный_A 0.5856714248657227\n",
            "тоскливый_A 0.5783498287200928\n",
            "кошмарный_A 0.5670032501220703\n",
            "гнетущий_A 0.5607054829597473\n",
            "чудовищный_A 0.5550791025161743\n",
            "мрачный_A 0.5542315244674683\n",
            "\n",
            "\n",
            "страшный_A\n",
            "[-0.12759186 -0.0206753   0.00979353 -0.02963523  0.03109632  0.02121338\n",
            " -0.02869159  0.02574235 -0.02556899 -0.03742376]\n",
            "ужасный_A 0.8007251620292664\n",
            "жуткий_A 0.6917036175727844\n",
            "чудовищный_A 0.5934231877326965\n",
            "кошмарный_A 0.539563000202179\n",
            "отвратительный_A 0.5351147651672363\n",
            "невероятный_A 0.5207849144935608\n",
            "ужасающий_A 0.5174921154975891\n",
            "зловещий_A 0.5163233876228333\n",
            "жестокий_A 0.5096044540405273\n",
            "ужасать_V 0.5071669816970825\n",
            "\n",
            "\n",
            "красный_A\n",
            "[ 0.01627072 -0.01136785 -0.00790482  0.02294072  0.05129128  0.10162549\n",
            "  0.07488654 -0.06475785 -0.0203686   0.09159683]\n",
            "алый_A 0.6421287059783936\n",
            "малиновый_A 0.6113021373748779\n",
            "красная_S 0.5526680946350098\n",
            "желтый_A 0.5431625843048096\n",
            "оранжевый_A 0.5371882319450378\n",
            "трехцветный_A 0.5317935347557068\n",
            "пунцовый_A 0.5125025510787964\n",
            "синий_A 0.5102002024650574\n",
            "фиолетовый_A 0.5072877407073975\n",
            "лиловый_A 0.5004071593284607\n",
            "\n",
            "\n",
            "синий_A\n",
            "[-0.00614284  0.04970241 -0.00461786 -0.11465221  0.08177482  0.00020589\n",
            "  0.04895581  0.02750725 -0.05211812  0.06006202]\n",
            "голубой_A 0.855513334274292\n",
            "темно-синий_A 0.7498062252998352\n",
            "оранжевый_A 0.7341034412384033\n",
            "лиловый_A 0.7314398884773254\n",
            "фиолетовый_A 0.7291390895843506\n",
            "желтый_A 0.7263568639755249\n",
            "ярко-синий_A 0.699012815952301\n",
            "черный_A 0.690920889377594\n",
            "зеленый_A 0.6799379587173462\n",
            "коричневый_A 0.6729934215545654\n",
            "\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiZ2jQHEVEIu",
        "outputId": "0098036c-d2dc-4488-888a-7072c5fcdbb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Находим косинусную близость пары слов:"
      ],
      "metadata": {
        "id": "2Mdpu0ztVEIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "print(model.similarity('плохой_A', 'хороший_A'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.74635214\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37gfNT_-VEIw",
        "outputId": "0251bf5f-2d93-431d-ffd6-4c34cfe6cc5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "print(model.similarity('плохой_A', 'синий_A'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.12778337\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF1gSK93VEIy",
        "outputId": "3129f4f1-29e3-486a-a271-619140718133"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "print(model.similarity('ужасный_A', 'жуткий_A'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.69825286\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdIxSXfpVEIz",
        "outputId": "13872e05-029c-4eed-942c-afe20cb6416b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем составить пропорцию:\n",
        "\n",
        "+ positive — вектора, которые мы складываем\n",
        "+ negative — вектора, которые вычитаем"
      ],
      "metadata": {
        "id": "IN24380IVEI0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "print(model.most_similar(positive=['плохой_A', 'ужасный_A'], negative=['хороший_A'])[0][0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "страшный_A\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_8WiWZpVEI1",
        "outputId": "d882392f-96b0-41e5-a7b7-af07a956d207"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найди лишнее!"
      ],
      "metadata": {
        "id": "F5VLNFUhVEI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "print(model.doesnt_match('плохой_A хороший_A ужасный_A страшный_A'.split()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хороший_A\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Eqd1B2VEI4",
        "outputId": "32b8cb69-d968-4817-a014-d63ca4cdf5ce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "print(model.doesnt_match('плохой_A ужасный_A страшный_A'.split()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "плохой_A\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da5fov1DVEI5",
        "outputId": "2319db02-f2ff-4ded-ad0d-37fd19504570"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "for word, score in model.most_similar(positive=['ужасно_ADV'], negative=['плохой_A']):\n",
        "    print(f'{score:.4}\\t{word}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5575\tбезумно_ADV\n",
            "0.4791\tбезмерно_ADV\n",
            "0.4536\tжутко_ADV\n",
            "0.4472\tневероятно_ADV\n",
            "0.4394\tочень_ADV\n",
            "0.4364\tчертовски_ADV\n",
            "0.4231\tстрашно_ADV\n",
            "0.4124\tнеобычайно_ADV\n",
            "0.4119\tнестерпимо_ADV\n",
            "0.4005\tнеобыкновенно_ADV\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJndzvCqVEI6",
        "outputId": "f7d650b5-470c-450f-acd1-cd209806cf25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что означают полученные результаты для нашего исследования? Объединяет ли модель *плохой, ужасный, жуткий, страшный* по отрицательной полярности и объединяет ли она *ужасный, жуткий, страшный* по функции интенсификации?"
      ],
      "metadata": {
        "id": "-R0i47cLVEI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Визуализация\n",
        "\n",
        "Можно использовать разные методы того, как преобразовать векторы так, чтобы можно было их поместить на двумерное пространство, например, с помощью PCA. В зависимости от того, относительно какого набора слов вы пытаетесь найти оптимально отображение на двумерное пространство, у вас могут получаться разные результаты"
      ],
      "metadata": {
        "id": "PjRcz2nrVEI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "DTpnk9BsVEI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']\n",
        "X = model[words]#model.wv[words]"
      ],
      "outputs": [],
      "metadata": {
        "id": "GVk5tY3WVEI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "pca = PCA(n_components=2)\n",
        "coords = pca.fit_transform(X)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QHCQntR-VEI_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
        "plt.title('Words')\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hVia6FDvVEJD",
        "outputId": "aadb2d0d-462a-4ee6-9eb6-c3d1124710b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Оценка\n",
        "\n",
        "Это, конечно, хорошо, но как понять, какая модель лучше? Или вот, например, я сделал свою модель, а как понять, насколько она хорошая?\n",
        "\n",
        "Для этого существуют специальные датасеты для оценки качества дистрибутивных моделей. Основных два: один измеряет точность решения задач на аналогии, а второй используется для оценки коэффициента семантической близости.\n",
        "\n",
        "#### Word Similarity\n",
        "\n",
        "Этот метод заключается в том, чтобы оценить, насколько представления о семантической близости слов в модели соотносятся с \"представлениями\" людей.\n",
        "\n",
        "| слово 1    | слово 2    | близость |\n",
        "|------------|------------|----------|\n",
        "| кошка      | собака     | 0.7      | \n",
        "| чашка      | кружка     | 0.9      | \n",
        "\n",
        "Для каждой пары слов из заранее заданного датасета мы можем посчитать косинусное расстояние, и получить список таких значений близости. При этом у нас уже есть список значений близостей, сделанный людьми. Мы можем сравнить эти два списка и понять, насколько они похожи (например, посчитав корреляцию). Эта мера схожести должна говорить о том, насколько модель хорошо моделирует расстояния о слова.\n",
        "\n",
        "#### Аналогии\n",
        "\n",
        "Другая популярная задача для \"внутренней\" оценки называется задачей поиска аналогий. Как мы уже разбирали выше, с помощью простых арифметических операций мы можем модифицировать значение слова. Если заранее собрать набор слов-модификаторов, а также слов, которые мы хотим получить в результаты модификации, то на основе подсчёта количества \"попаданий\" в желаемое слово мы можем оценить, насколько хорошо работает модель.\n",
        "\n",
        "В качестве слов-модификатор мы можем использовать семантические аналогии. Скажем, если у нас есть некоторое отношение \"страна-столица\", то для оценки модели мы можем использовать пары наподобие \"Россия-Москва\", \"Норвегия-Осло\", и т.д. Датасет будет выглядеть следующм образом:\n",
        "\n",
        "| слово 1    | слово 2    | отношение     | \n",
        "|------------|------------|---------------|\n",
        "| Россия     | Москва     | страна-столица| \n",
        "| Норвегия   | Осло       | страна-столица|\n",
        "\n",
        "Рассматривая случайные две пары из этого набора, мы хотим, имея триплет (Россия, Москва, Норвегия) хотим получить слово \"Осло\", т.е. найти такое слово, которое будет находиться в том же отношении со словом \"Норвегия\", как \"Россия\" находится с Москвой.\n",
        "\n",
        "Датасеты для русского языка можно скачать на странице с моделями на RusVectores. Посчитаем качество нашей модели НКРЯ на датасете про аналогии:"
      ],
      "metadata": {
        "id": "TAJ4CiDDVEJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# res = model.accuracy('ru_analogy_tagged.txt') # работает для старых версий gensim"
      ],
      "outputs": [],
      "metadata": {
        "id": "Uy2hyRVnVEJK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# for row in res[4]['incorrect'][:10]:\n",
        "#     print('\\t'.join(row))"
      ],
      "outputs": [],
      "metadata": {
        "id": "VQt_47fgVEJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Задание 1\n",
        "\n",
        "+ Возьмите небольшой кусочек текста или стихотворение.\n",
        "+ Замените все неслужебные слова в нём на их ближайших соседей из нашей модели.\n",
        "+ Прокомментируйте результат.\n",
        "\n",
        "#### Задание 2\n",
        "\n",
        "+ Возьмите интересный Вам текст.\n",
        "+ Лемматизируйте текст, отчистите от пунктуации и служебной информации и обучите на нем модель word2vec (поэкспериментируйте с размером окна, с длиной вектора). \n",
        "+ Найдите по 5 ближайших слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы). Учтите, что слова может не быть в модели!\n",
        "+ Найдите по 5 \"далёких\" слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы).\n",
        "+ Прокомментируйте результат."
      ],
      "metadata": {
        "id": "DCRWEaEuVEJL"
      }
    }
  ]
}